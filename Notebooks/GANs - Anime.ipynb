{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Preprocessing-Images\" data-toc-modified-id=\"Preprocessing-Images-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing Images</a></span></li><li><span><a href=\"#GANs:-Discrimator-and-Generator\" data-toc-modified-id=\"GANs:-Discrimator-and-Generator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>GANs: Discrimator and Generator</a></span></li><li><span><a href=\"#Training-NNs\" data-toc-modified-id=\"Training-NNs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training NNs</a></span></li><li><span><a href=\"#Testing-NNs\" data-toc-modified-id=\"Testing-NNs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Testing NNs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs for Anime Faces\n",
    "\n",
    "The main idea of this notebook is to use GANs in order to generate fake anime faces. I would use the tutorial [GANs from Scratch 1: A deep introduction. With code in PyTorch and TensorFlow](https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f).\n",
    "\n",
    "By the end of this little project, I hope to have some realistic anime faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:42:52.556853Z",
     "start_time": "2020-03-23T20:42:49.565852Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "# from utils import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This section contains the functions that will be used in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:42:52.570345Z",
     "start_time": "2020-03-23T20:42:52.559660Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the required functions\n",
    "def images_to_vectors(images, value):\n",
    "    return images.view(images.size(0), value)\n",
    "\n",
    "def vectors_to_images(vectors, rows, cols):\n",
    "    return vectors.view(vectors.size(0), 1, rows, cols)\n",
    "\n",
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    return n\n",
    "\n",
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:42:52.878547Z",
     "start_time": "2020-03-23T20:42:52.573477Z"
    }
   },
   "outputs": [],
   "source": [
    "#Execute the file Logger.py\n",
    "exec(open('../Scripts/Logger.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Images\n",
    "\n",
    "This section contains the reading and preprocessing of the anime faces obtained in [Anime Faces](https://www.kaggle.com/soumikrakshit/anime-faces/data) and the ones thanks to [Brian Chao](https://github.com/Mckinsey666) and his repostory [Anime-Face-Dataset](https://github.com/Mckinsey666/Anime-Face-Dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:43:06.340010Z",
     "start_time": "2020-03-23T20:43:06.335199Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create transformers image to tensor and tensor to image \n",
    "trans_0 = transforms.ToPILImage()\n",
    "trans_1 = transforms.ToTensor()\n",
    "trans_2 = transforms.Normalize(mean=(0.5,), std=(0.5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:43:51.358926Z",
     "start_time": "2020-03-23T20:43:06.739591Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE NUMBER 4000\n",
      "IMAGE NUMBER 8000\n",
      "IMAGE NUMBER 12000\n",
      "IMAGE NUMBER 16000\n",
      "IMAGE NUMBER 20000\n",
      "NON CHARGED 0 IMAGES\n"
     ]
    }
   ],
   "source": [
    "#Read the images and createds a list with the images in tensor format\n",
    "images_path = glob.glob(\"../Images/*png\")\n",
    "images_data = []\n",
    "no_charged = 0\n",
    "for idx, image in enumerate(images_path):\n",
    "    try:\n",
    "        img = Image.open(image)\n",
    "        img_tensor = trans_2(trans_1(transforms.functional.to_grayscale(img)))\n",
    "        images_data.append(img_tensor)\n",
    "    except:\n",
    "        no_charged += 1\n",
    "        pass\n",
    "    if idx % 4000 == 0 and idx > 0:\n",
    "        print('IMAGE NUMBER', idx)\n",
    "#Print the number of images non charged\n",
    "print('NON CHARGED', no_charged, 'IMAGES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:53:59.488930Z",
     "start_time": "2020-03-23T20:53:59.481748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156 BACHTES\n"
     ]
    }
   ],
   "source": [
    "#Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(images_data, batch_size=10, shuffle=True)\n",
    "num_batches = len(data_loader)\n",
    "print(num_batches, 'BACHTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:00.082437Z",
     "start_time": "2020-03-23T20:54:00.077144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n"
     ]
    }
   ],
   "source": [
    "pixel_rows = images_data[0].shape[1]\n",
    "pixel_cols = images_data[0].shape[2]\n",
    "print(pixel_rows, pixel_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs: Discrimator and Generator\n",
    "\n",
    "In this section we define the architecture of the two neural networks: the discriminator and the generator using the code in [GANs from Scratch 1: A deep introduction. With code in PyTorch and TensorFlow](https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:00.798069Z",
     "start_time": "2020-03-23T20:54:00.751683Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = pixel_rows*pixel_cols\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "discriminator = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:01.019438Z",
     "start_time": "2020-03-23T20:54:00.953250Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out =  pixel_rows*pixel_cols\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "generator = GeneratorNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NNs\n",
    "\n",
    "This section trains the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:01.326590Z",
     "start_time": "2020-03-23T20:54:01.313358Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the optimizers and lossfor the NNs\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:01.515375Z",
     "start_time": "2020-03-23T20:54:01.506080Z"
    }
   },
   "outputs": [],
   "source": [
    "#Trains the discriminator with real and fake data \n",
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    N = real_data.size(0)\n",
    "    #Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, ones_target(N) )\n",
    "    error_real.backward()\n",
    "\n",
    "    #1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, zeros_target(N))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    #1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Return error and predictions for real and fake inputs\n",
    "    return error_real + error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:01.660115Z",
     "start_time": "2020-03-23T20:54:01.653864Z"
    }
   },
   "outputs": [],
   "source": [
    "#Trains the generator of fake data\n",
    "def train_generator(optimizer, fake_data):\n",
    "    N = fake_data.size(0)\n",
    "    \n",
    "    #Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    \n",
    "    #Calculate error and backpropagate\n",
    "    error = loss(prediction, ones_target(N))\n",
    "    error.backward()\n",
    "    \n",
    "    #Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:54:01.816851Z",
     "start_time": "2020-03-23T20:54:01.808742Z"
    }
   },
   "outputs": [],
   "source": [
    "#Noise every single sixteen steps to see what happens\n",
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing NNs\n",
    "\n",
    "This sections generates the fake anime faces and allows us to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:48:52.518362Z",
     "start_time": "2020-03-24T00:48:52.514461Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create logger instance\n",
    "logger = Logger(model_name='VGAN', data_name='ANIME-FACES')\n",
    "#Total number of epochs to train\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, real_batch in enumerate(data_loader):\n",
    "        N = real_batch.size(0)\n",
    "        #1. Train Discriminator\n",
    "        real_data = Variable(images_to_vectors(real_batch, value=pixel_rows*pixel_cols))\n",
    "        #Generate fake data and detach \n",
    "        #(so gradients are not calculated for generator)\n",
    "        fake_data = generator(noise(N)).detach()\n",
    "        #Train Discriminator\n",
    "        d_error, d_pred_real, d_pred_fake = \\\n",
    "              train_discriminator(d_optimizer, real_data, fake_data)\n",
    "\n",
    "        #2. Train Generator\n",
    "        #Generate fake data\n",
    "        fake_data = generator(noise(N))\n",
    "        #Train Generator\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        #Log batch error\n",
    "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "        #Display Progress every few batches\n",
    "        if (n_batch) % 100 == 0: \n",
    "            test_images = vectors_to_images(generator(test_noise), rows=pixel_rows, cols=pixel_cols)\n",
    "            test_images = test_images.data\n",
    "            logger.log_images(\n",
    "                test_images, num_test_samples, \n",
    "                epoch, n_batch, num_batches\n",
    "            );\n",
    "            #Display status Logs\n",
    "            logger.display_status(\n",
    "                epoch, num_epochs, n_batch, num_batches,\n",
    "                d_error, g_error, d_pred_real, d_pred_fake\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
